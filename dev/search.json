[{"path":[]},{"path":"https://probably.tidymodels.org/dev/CODE_OF_CONDUCT.html","id":"our-pledge","dir":"","previous_headings":"","what":"Our Pledge","title":"Contributor Covenant Code of Conduct","text":"members, contributors, leaders pledge make participation community harassment-free experience everyone, regardless age, body size, visible invisible disability, ethnicity, sex characteristics, gender identity expression, level experience, education, socio-economic status, nationality, personal appearance, race, caste, color, religion, sexual identity orientation. pledge act interact ways contribute open, welcoming, diverse, inclusive, healthy community.","code":""},{"path":"https://probably.tidymodels.org/dev/CODE_OF_CONDUCT.html","id":"our-standards","dir":"","previous_headings":"","what":"Our Standards","title":"Contributor Covenant Code of Conduct","text":"Examples behavior contributes positive environment community include: Demonstrating empathy kindness toward people respectful differing opinions, viewpoints, experiences Giving gracefully accepting constructive feedback Accepting responsibility apologizing affected mistakes, learning experience Focusing best just us individuals, overall community Examples unacceptable behavior include: use sexualized language imagery, sexual attention advances kind Trolling, insulting derogatory comments, personal political attacks Public private harassment Publishing others’ private information, physical email address, without explicit permission conduct reasonably considered inappropriate professional setting","code":""},{"path":"https://probably.tidymodels.org/dev/CODE_OF_CONDUCT.html","id":"enforcement-responsibilities","dir":"","previous_headings":"","what":"Enforcement Responsibilities","title":"Contributor Covenant Code of Conduct","text":"Community leaders responsible clarifying enforcing standards acceptable behavior take appropriate fair corrective action response behavior deem inappropriate, threatening, offensive, harmful. Community leaders right responsibility remove, edit, reject comments, commits, code, wiki edits, issues, contributions aligned Code Conduct, communicate reasons moderation decisions appropriate.","code":""},{"path":"https://probably.tidymodels.org/dev/CODE_OF_CONDUCT.html","id":"scope","dir":"","previous_headings":"","what":"Scope","title":"Contributor Covenant Code of Conduct","text":"Code Conduct applies within community spaces, also applies individual officially representing community public spaces. Examples representing community include using official e-mail address, posting via official social media account, acting appointed representative online offline event.","code":""},{"path":"https://probably.tidymodels.org/dev/CODE_OF_CONDUCT.html","id":"enforcement","dir":"","previous_headings":"","what":"Enforcement","title":"Contributor Covenant Code of Conduct","text":"Instances abusive, harassing, otherwise unacceptable behavior may reported community leaders responsible enforcement codeofconduct@rstudio.com. complaints reviewed investigated promptly fairly. community leaders obligated respect privacy security reporter incident.","code":""},{"path":"https://probably.tidymodels.org/dev/CODE_OF_CONDUCT.html","id":"enforcement-guidelines","dir":"","previous_headings":"","what":"Enforcement Guidelines","title":"Contributor Covenant Code of Conduct","text":"Community leaders follow Community Impact Guidelines determining consequences action deem violation Code Conduct:","code":""},{"path":"https://probably.tidymodels.org/dev/CODE_OF_CONDUCT.html","id":"id_1-correction","dir":"","previous_headings":"Enforcement Guidelines","what":"1. Correction","title":"Contributor Covenant Code of Conduct","text":"Community Impact: Use inappropriate language behavior deemed unprofessional unwelcome community. Consequence: private, written warning community leaders, providing clarity around nature violation explanation behavior inappropriate. public apology may requested.","code":""},{"path":"https://probably.tidymodels.org/dev/CODE_OF_CONDUCT.html","id":"id_2-warning","dir":"","previous_headings":"Enforcement Guidelines","what":"2. Warning","title":"Contributor Covenant Code of Conduct","text":"Community Impact: violation single incident series actions. Consequence: warning consequences continued behavior. interaction people involved, including unsolicited interaction enforcing Code Conduct, specified period time. includes avoiding interactions community spaces well external channels like social media. Violating terms may lead temporary permanent ban.","code":""},{"path":"https://probably.tidymodels.org/dev/CODE_OF_CONDUCT.html","id":"id_3-temporary-ban","dir":"","previous_headings":"Enforcement Guidelines","what":"3. Temporary Ban","title":"Contributor Covenant Code of Conduct","text":"Community Impact: serious violation community standards, including sustained inappropriate behavior. Consequence: temporary ban sort interaction public communication community specified period time. public private interaction people involved, including unsolicited interaction enforcing Code Conduct, allowed period. Violating terms may lead permanent ban.","code":""},{"path":"https://probably.tidymodels.org/dev/CODE_OF_CONDUCT.html","id":"id_4-permanent-ban","dir":"","previous_headings":"Enforcement Guidelines","what":"4. Permanent Ban","title":"Contributor Covenant Code of Conduct","text":"Community Impact: Demonstrating pattern violation community standards, including sustained inappropriate behavior, harassment individual, aggression toward disparagement classes individuals. Consequence: permanent ban sort public interaction within community.","code":""},{"path":"https://probably.tidymodels.org/dev/CODE_OF_CONDUCT.html","id":"attribution","dir":"","previous_headings":"","what":"Attribution","title":"Contributor Covenant Code of Conduct","text":"Code Conduct adapted Contributor Covenant, version 2.1, available https://www.contributor-covenant.org/version/2/1/code_of_conduct.html. Community Impact Guidelines inspired [Mozilla’s code conduct enforcement ladder][https://github.com/mozilla/inclusion]. answers common questions code conduct, see FAQ https://www.contributor-covenant.org/faq. Translations available https://www.contributor-covenant.org/translations.","code":""},{"path":"https://probably.tidymodels.org/dev/LICENSE.html","id":null,"dir":"","previous_headings":"","what":"MIT License","title":"MIT License","text":"Copyright (c) 2021 probably authors Permission hereby granted, free charge, person obtaining copy software associated documentation files (“Software”), deal Software without restriction, including without limitation rights use, copy, modify, merge, publish, distribute, sublicense, /sell copies Software, permit persons Software furnished , subject following conditions: copyright notice permission notice shall included copies substantial portions Software. SOFTWARE PROVIDED “”, WITHOUT WARRANTY KIND, EXPRESS IMPLIED, INCLUDING LIMITED WARRANTIES MERCHANTABILITY, FITNESS PARTICULAR PURPOSE NONINFRINGEMENT. EVENT SHALL AUTHORS COPYRIGHT HOLDERS LIABLE CLAIM, DAMAGES LIABILITY, WHETHER ACTION CONTRACT, TORT OTHERWISE, ARISING , CONNECTION SOFTWARE USE DEALINGS SOFTWARE.","code":""},{"path":"https://probably.tidymodels.org/dev/articles/equivocal-zones.html","id":"equivocal-zones","dir":"Articles","previous_headings":"","what":"Equivocal zones","title":"Equivocal zones","text":"fields, class probability predictions must meet certain standards firm decision can made using . fail standards, prediction can marked equivocal, just means unsure true result. might want investigate equivocal values, rerun whatever process generated proceeding. example, binary model, prediction returned probability values 52% Yes 48% , really sure isn’t just random noise? case, use buffer surrounding threshold 50% determine whether model sure predictions, mark values unsure equivocal. Another example come Bayesian perspective, prediction comes probability distribution. model might predict 80% Yes, standard deviation around +/- 20%. case, set maximum allowed standard deviation cutoff whether mark values equivocal. work equivocal zones, probably provides new class hard class predictions similar factor, allows mark certain values equivocal. reportable rate fraction values equivocal, relative total number. , can see reportable rate started 100%, soon single value marked equivocal, value dropped 75%. fields equivocal zones used, often tradeoff marking values equivocal keeping certain minimum reportable rate. Generally, won’t create class_pred objects directly, instead create indirectly converting class probabilities class predictions make_class_pred() make_two_class_pred(). buffer used, equivocal zone created around threshold threshold +/- buffer values inside zone automatically marked equivocal. Equivocal values class_pred objects converted NA object converted factor. ’s also worth noting [EQ] label treated separate level. NA behavior feeds probably can used yardstick. Generally, equivocal values removed completely performance evaluation. converting NA leaving default na_rm = TRUE yardstick metric removes consideration. seen , removing equivocal values using simple threshold generally improves performance values model unsure removed. don’t fooled! give cases extra consideration, remember reportable rate decreased removing . production, ’ll likely something predictions!","code":"x <- factor(c(\"Yes\", \"No\", \"Yes\", \"Yes\"))  # Create a class_pred object from a factor class_pred(x) #> [1] Yes No  Yes Yes #> Levels: No Yes #> Reportable: 100%  # Say you aren't sure about that 2nd \"Yes\" value.  # You could mark it as equivocal. class_pred(x, which = 3) #> [1] Yes  No   [EQ] Yes  #> Levels: No Yes #> Reportable: 75% library(dplyr) data(\"segment_logistic\") segment_logistic #> # A tibble: 1,010 × 3 #>    .pred_poor .pred_good Class #>  *      <dbl>      <dbl> <fct> #>  1    0.986      0.0142  poor  #>  2    0.897      0.103   poor  #>  3    0.118      0.882   good  #>  4    0.102      0.898   good  #>  5    0.991      0.00914 poor  #>  6    0.633      0.367   good  #>  7    0.770      0.230   good  #>  8    0.00842    0.992   good  #>  9    0.995      0.00458 poor  #> 10    0.765      0.235   poor  #> # … with 1,000 more rows  # Convert probabilities into predictions # > 0.5 = good # < 0.5 = poor segment_logistic_thresh <- segment_logistic %>%   mutate(     .pred = make_two_class_pred(       estimate = .pred_good,        levels = levels(Class),        threshold = 0.5     )   )  segment_logistic_thresh #> # A tibble: 1,010 × 4 #>    .pred_poor .pred_good Class      .pred #>         <dbl>      <dbl> <fct> <clss_prd> #>  1    0.986      0.0142  poor        poor #>  2    0.897      0.103   poor        poor #>  3    0.118      0.882   good        good #>  4    0.102      0.898   good        good #>  5    0.991      0.00914 poor        poor #>  6    0.633      0.367   good        poor #>  7    0.770      0.230   good        poor #>  8    0.00842    0.992   good        good #>  9    0.995      0.00458 poor        poor #> 10    0.765      0.235   poor        poor #> # … with 1,000 more rows # Convert probabilities into predictions #        x > 0.55 = good #        x < 0.45 = poor # 0.45 < x < 0.55 = equivocal segment_pred <- segment_logistic %>%   mutate(     .pred = make_two_class_pred(       estimate = .pred_good,        levels = levels(Class),        threshold = 0.5,       buffer = 0.05     )   )   segment_pred %>%   count(.pred) #> # A tibble: 3 × 2 #>        .pred     n #>   <clss_prd> <int> #> 1       [EQ]    45 #> 2       good   340 #> 3       poor   625  segment_pred %>%   summarise(reportable = reportable_rate(.pred)) #> # A tibble: 1 × 1 #>   reportable #>        <dbl> #> 1      0.955 segment_pred %>%   mutate(.pred_fct = as.factor(.pred)) %>%   count(.pred, .pred_fct) #> # A tibble: 3 × 3 #>        .pred .pred_fct     n #>   <clss_prd> <fct>     <int> #> 1       [EQ] NA           45 #> 2       good good        340 #> 3       poor poor        625  levels(segment_pred$.pred) #> [1] \"good\" \"poor\" library(yardstick) #> For binary classification, the first factor level is assumed to be the event. #> Use the argument `event_level = \"second\"` to alter this as needed.  # No equivocal zone segment_logistic_thresh %>%   mutate(.pred_fct = as.factor(.pred)) %>%   precision(Class, .pred_fct) #> # A tibble: 1 × 3 #>   .metric   .estimator .estimate #>   <chr>     <chr>          <dbl> #> 1 precision binary         0.680  # Equivocal zone segment_pred %>%   mutate(.pred_fct = as.factor(.pred)) %>%   precision(Class, .pred_fct) #> # A tibble: 1 × 3 #>   .metric   .estimator .estimate #>   <chr>     <chr>          <dbl> #> 1 precision binary         0.694"},{"path":"https://probably.tidymodels.org/dev/articles/where-to-use.html","id":"introduction","dir":"Articles","previous_headings":"","what":"Introduction","title":"Where does probably fit in?","text":"obvious question regarding probably might : fit rest tidymodels ecosystem? Like pieces ecosystem, probably designed modular, plays well tidymodels packages. Regarding placement modeling workflow, probably best fits post processing step model fit, model performance calculated.","code":""},{"path":"https://probably.tidymodels.org/dev/articles/where-to-use.html","id":"example","dir":"Articles","previous_headings":"","what":"Example","title":"Where does probably fit in?","text":"example, ’ll use parsnip fit logistic regression Lending Club loan data, use probably investigate happens performance vary threshold “good” loan . Let’s split 75% training 25% testing something predict . anything, let’s look counts going predicting, Class loan. Clearly large imbalance number good bad loans. probably good thing bank, poses interesting issue us might want ensure sensitive bad loans overwhelmed number good ones. One thing might downsample number good loans total number line number bad loans. fitting model using themis::step_downsample(), now, let’s continue data unchanged. ’ll use parsnip’s logistic_reg() create model specification logistic regression, set engine glm actually fit model using data model formula. output parsnip fit() call parsnip model_fit object, underlying print method glm fit used. Now let’s predict testing set, use type = \"prob\" get class probabilities back rather hard predictions. use probably investigate performance. class probabilities hand, can use make_two_class_pred() convert probabilities hard predictions using threshold. threshold 0.5 just says predicted probability 0.5, classify prediction “good” loan, otherwise, bad. Hmm, 0.5 threshold, almost loans predicted “good”. Perhaps something large class imbalance. hand, bank might want stringent classified “good” loan, might require probability 0.75 threshold. case, 4 bad loans correctly classified bad, good loans also misclassified bad now. tradeoff , can somewhat captured metrics sensitivity specificity. metrics max value 1. sensitivity - proportion predicted “good” loans “good” loans specificity - proportion predicted “bad” loans “bad” loans example, increased specificity (capturing 4 bad loans higher threshold), lowered sensitivity (incorrectly reclassifying good loans bad). nice combination metrics represent tradeoff. Luckily, j_index exactly . \\[ j\\_index = sens + spec - 1 \\] j_index maximum value 1 false positives false negatives. can used justification whether increase threshold value worth . increasing threshold results increase specificity decrease sensitivity, can see j_index. Now, way optimize things. care low false positives, might interested keeping sensitivity high, wouldn’t best way tackle problem. now, let’s see can use probably optimize j_index. threshold_perf() recalculate number metrics across varying thresholds. One j_index. ggplot2, can easily visualize varying performance find optimal threshold maximizing j_index.  ’s clear visual optimal threshold high, exactly 0.945. pretty high, , optimization method won’t useful cases. wrap , test set metrics threshold value.","code":"library(parsnip) library(probably) library(dplyr) library(rsample) library(modeldata) data(\"lending_club\")  # I think it makes more sense to have \"good\" as the first level # By default it comes as the second level lending_club <- lending_club %>%   mutate(Class = relevel(Class, \"good\"))  # There are a number of columns in this data set, but we will only use a few # for this example lending_club <- select(lending_club, Class, annual_inc, verification_status, sub_grade)  lending_club #> # A tibble: 9,857 × 4 #>    Class annual_inc verification_status sub_grade #>    <fct>      <dbl> <fct>               <fct>     #>  1 good       35000 Not_Verified        C4        #>  2 good       72000 Verified            C1        #>  3 good       72000 Source_Verified     D1        #>  4 good      101000 Verified            C3        #>  5 good       50100 Source_Verified     A4        #>  6 good       32000 Source_Verified     B5        #>  7 good       65000 Not_Verified        A1        #>  8 good      188000 Not_Verified        B2        #>  9 good       89000 Source_Verified     B3        #> 10 good       48000 Not_Verified        C2        #> # … with 9,847 more rows # 75% train, 25% test set.seed(123)  split <- initial_split(lending_club, prop = 0.75)  lending_train <- training(split) lending_test  <- testing(split) count(lending_train, Class) #> # A tibble: 2 × 2 #>   Class     n #>   <fct> <int> #> 1 good   7008 #> 2 bad     384 logi_reg <- logistic_reg() logi_reg_glm <- logi_reg %>% set_engine(\"glm\")  # A small model specification that defines the type of model you are  # using and the engine logi_reg_glm #> Logistic Regression Model Specification (classification) #>  #> Computational engine: glm  # Fit the model logi_reg_fit <- fit(   logi_reg_glm,    formula = Class ~ annual_inc + verification_status + sub_grade,    data = lending_train )  logi_reg_fit #> parsnip model object #>  #>  #> Call:  stats::glm(formula = Class ~ annual_inc + verification_status +  #>     sub_grade, family = stats::binomial, data = data) #>  #> Coefficients: #>                        (Intercept)                          annual_inc   #>                         -5.670e+00                           1.915e-06   #> verification_statusSource_Verified         verification_statusVerified   #>                          4.324e-02                           3.364e-01   #>                        sub_gradeA2                         sub_gradeA3   #>                          9.508e-02                           1.149e+00   #>                        sub_gradeA4                         sub_gradeA5   #>                         -5.591e-02                           1.510e+00   #>                        sub_gradeB1                         sub_gradeB2   #>                          1.637e+00                           1.177e+00   #>                        sub_gradeB3                         sub_gradeB4   #>                          1.467e+00                           1.975e+00   #>                        sub_gradeB5                         sub_gradeC1   #>                          2.125e+00                           2.234e+00   #>                        sub_gradeC2                         sub_gradeC3   #>                          2.176e+00                           2.380e+00   #>                        sub_gradeC4                         sub_gradeC5   #>                          2.724e+00                           3.084e+00   #>                        sub_gradeD1                         sub_gradeD2   #>                          3.105e+00                           2.816e+00   #>                        sub_gradeD3                         sub_gradeD4   #>                          3.165e+00                           3.125e+00   #>                        sub_gradeD5                         sub_gradeE1   #>                          3.507e+00                           3.621e+00   #>                        sub_gradeE2                         sub_gradeE3   #>                          3.272e+00                           3.542e+00   #>                        sub_gradeE4                         sub_gradeE5   #>                          3.428e+00                           3.468e+00   #>                        sub_gradeF1                         sub_gradeF2   #>                          3.717e+00                           4.096e+00   #>                        sub_gradeF3                         sub_gradeF4   #>                          3.681e+00                           3.662e+00   #>                        sub_gradeF5                         sub_gradeG1   #>                          3.586e+00                           4.168e+00   #>                        sub_gradeG2                         sub_gradeG3   #>                          4.162e+00                           4.422e+00   #>                        sub_gradeG4                         sub_gradeG5   #>                          5.102e+00                          -8.226e+00   #>  #> Degrees of Freedom: 7391 Total (i.e. Null);  7354 Residual #> Null Deviance:       3019  #> Residual Deviance: 2716  AIC: 2792 predictions <- logi_reg_fit %>%   predict(new_data = lending_test, type = \"prob\")  head(predictions, n = 2) #> # A tibble: 2 × 2 #>   .pred_good .pred_bad #>        <dbl>     <dbl> #> 1      0.969    0.0311 #> 2      0.965    0.0353  lending_test_pred <- bind_cols(predictions, lending_test)  lending_test_pred #> # A tibble: 2,465 × 6 #>    .pred_good .pred_bad Class annual_inc verification_status sub_grade #>         <dbl>     <dbl> <fct>      <dbl> <fct>               <fct>     #>  1      0.969   0.0311  good       32000 Source_Verified     B5        #>  2      0.965   0.0353  good       73400 Source_Verified     C2        #>  3      0.960   0.0405  good      175000 Source_Verified     B5        #>  4      0.972   0.0276  good       70000 Not_Verified        B4        #>  5      0.874   0.126   good       36000 Source_Verified     E1        #>  6      0.944   0.0560  good       40000 Source_Verified     C4        #>  7      0.996   0.00385 good       60000 Not_Verified        A1        #>  8      0.951   0.0486  good       65000 Verified            C1        #>  9      0.963   0.0370  good       52000 Verified            B4        #> 10      0.983   0.0173  good       61000 Verified            B2        #> # … with 2,455 more rows hard_pred_0.5 <- lending_test_pred %>%   mutate(     .pred = make_two_class_pred(       estimate = .pred_good,        levels = levels(Class),        threshold = .5     )   ) %>%   select(Class, contains(\".pred\"))  hard_pred_0.5 %>%    count(.truth = Class, .pred) #> # A tibble: 2 × 3 #>   .truth      .pred     n #>   <fct>  <clss_prd> <int> #> 1 good         good  2332 #> 2 bad          good   133 hard_pred_0.75 <- lending_test_pred %>%   mutate(     .pred = make_two_class_pred(       estimate = .pred_good,        levels = levels(Class),        threshold = .75     )   ) %>%   select(Class, contains(\".pred\"))  hard_pred_0.75 %>%    count(.truth = Class, .pred) #> # A tibble: 4 × 3 #>   .truth      .pred     n #>   <fct>  <clss_prd> <int> #> 1 good         good  2320 #> 2 good          bad    12 #> 3 bad          good   129 #> 4 bad           bad     4 library(yardstick) #> For binary classification, the first factor level is assumed to be the event. #> Use the argument `event_level = \"second\"` to alter this as needed.  sens(hard_pred_0.5, Class, .pred) #> # A tibble: 1 × 3 #>   .metric .estimator .estimate #>   <chr>   <chr>          <dbl> #> 1 sens    binary             1 spec(hard_pred_0.5, Class, .pred) #> # A tibble: 1 × 3 #>   .metric .estimator .estimate #>   <chr>   <chr>          <dbl> #> 1 spec    binary             0  sens(hard_pred_0.75, Class, .pred) #> # A tibble: 1 × 3 #>   .metric .estimator .estimate #>   <chr>   <chr>          <dbl> #> 1 sens    binary         0.995 spec(hard_pred_0.75, Class, .pred) #> # A tibble: 1 × 3 #>   .metric .estimator .estimate #>   <chr>   <chr>          <dbl> #> 1 spec    binary        0.0301 j_index(hard_pred_0.5, Class, .pred) #> # A tibble: 1 × 3 #>   .metric .estimator .estimate #>   <chr>   <chr>          <dbl> #> 1 j_index binary             0 j_index(hard_pred_0.75, Class, .pred) #> # A tibble: 1 × 3 #>   .metric .estimator .estimate #>   <chr>   <chr>          <dbl> #> 1 j_index binary        0.0249 threshold_data <- lending_test_pred %>%   threshold_perf(Class, .pred_good, thresholds = seq(0.5, 1, by = 0.0025))  threshold_data %>%   filter(.threshold %in% c(0.5, 0.6, 0.7)) #> # A tibble: 12 × 4 #>    .threshold .metric  .estimator .estimate #>         <dbl> <chr>    <chr>          <dbl> #>  1        0.5 sens     binary        1      #>  2        0.6 sens     binary        0.999  #>  3        0.7 sens     binary        0.998  #>  4        0.5 spec     binary        0      #>  5        0.6 spec     binary        0.0226 #>  6        0.7 spec     binary        0.0226 #>  7        0.5 j_index  binary        0      #>  8        0.6 j_index  binary        0.0217 #>  9        0.7 j_index  binary        0.0208 #> 10        0.5 distance binary        1      #> 11        0.6 distance binary        0.955  #> 12        0.7 distance binary        0.955 library(ggplot2)  threshold_data <- threshold_data %>%   filter(.metric != \"distance\") %>%   mutate(group = case_when(     .metric == \"sens\" | .metric == \"spec\" ~ \"1\",     TRUE ~ \"2\"   ))  max_j_index_threshold <- threshold_data %>%   filter(.metric == \"j_index\") %>%   filter(.estimate == max(.estimate)) %>%   pull(.threshold)  ggplot(threshold_data, aes(x = .threshold, y = .estimate, color = .metric, alpha = group)) +   geom_line() +   theme_minimal() +   scale_color_viridis_d(end = 0.9) +   scale_alpha_manual(values = c(.4, 1), guide = \"none\") +   geom_vline(xintercept = max_j_index_threshold, alpha = .6, color = \"grey30\") +   labs(     x = \"'Good' Threshold\\n(above this value is considered 'good')\",     y = \"Metric Estimate\",     title = \"Balancing performance by varying the threshold\",     subtitle = \"Sensitivity or specificity alone might not be enough!\\nVertical line = Max J-Index\"   ) threshold_data %>%   filter(.threshold == max_j_index_threshold) #> # A tibble: 3 × 5 #>   .threshold .metric .estimator .estimate group #>        <dbl> <chr>   <chr>          <dbl> <chr> #> 1      0.945 sens    binary         0.687 1     #> 2      0.945 spec    binary         0.692 1     #> 3      0.945 j_index binary         0.379 2"},{"path":"https://probably.tidymodels.org/dev/authors.html","id":null,"dir":"","previous_headings":"","what":"Authors","title":"Authors and Citation","text":"Max Kuhn. Author, maintainer. Davis Vaughan. Author. . Copyright holder, funder.","code":""},{"path":"https://probably.tidymodels.org/dev/authors.html","id":"citation","dir":"","previous_headings":"","what":"Citation","title":"Authors and Citation","text":"Kuhn M, Vaughan D (2023). probably: Tools Post-Processing Class Probability Estimates. https://github.com/tidymodels/probably/, https://probably.tidymodels.org.","code":"@Manual{,   title = {probably: Tools for Post-Processing Class Probability Estimates},   author = {Max Kuhn and Davis Vaughan},   year = {2023},   note = {https://github.com/tidymodels/probably/, https://probably.tidymodels.org}, }"},{"path":[]},{"path":"https://probably.tidymodels.org/dev/index.html","id":"introduction","dir":"","previous_headings":"","what":"Introduction","title":"Tools for Post-Processing Class Probability Estimates","text":"probably contains tools facilitate activities : Conversion probabilities discrete class predictions. Investigating estimating optimal probability thresholds. Inclusion equivocal zones probabilities uncertain report prediction.","code":""},{"path":"https://probably.tidymodels.org/dev/index.html","id":"installation","dir":"","previous_headings":"","what":"Installation","title":"Tools for Post-Processing Class Probability Estimates","text":"can install probably CRAN : can install development version probably GitHub :","code":"install.packages(\"probably\") devtools::install_github(\"topepo/probably\")"},{"path":"https://probably.tidymodels.org/dev/index.html","id":"examples","dir":"","previous_headings":"","what":"Examples","title":"Tools for Post-Processing Class Probability Estimates","text":"Good places look examples using probably vignettes. vignette(\"equivocal-zones\", \"probably\") discusses new class_pred class probably provides working equivocal zones. vignette(\"--use\", \"probably\") discusses probably fits rest tidymodels ecosystem, provides example optimizing class probability thresholds.","code":""},{"path":"https://probably.tidymodels.org/dev/index.html","id":"contributing","dir":"","previous_headings":"","what":"Contributing","title":"Tools for Post-Processing Class Probability Estimates","text":"project released Contributor Code Conduct. contributing project, agree abide terms. questions discussions tidymodels packages, modeling, machine learning, please post RStudio Community. think encountered bug, please submit issue. Either way, learn create share reprex (minimal, reproducible example), clearly communicate code. Check details contributing guidelines tidymodels packages get help.","code":""},{"path":"https://probably.tidymodels.org/dev/reference/append_class_pred.html","id":null,"dir":"Reference","previous_headings":"","what":"Add a class_pred column — append_class_pred","title":"Add a class_pred column — append_class_pred","text":"function similar make_class_pred(), useful large number class probability columns want use tidyselect helpers. appends new class_pred vector column original data frame.","code":""},{"path":"https://probably.tidymodels.org/dev/reference/append_class_pred.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Add a class_pred column — append_class_pred","text":"","code":"append_class_pred(   .data,   ...,   levels,   ordered = FALSE,   min_prob = 1/length(levels),   name = \".class_pred\" )"},{"path":"https://probably.tidymodels.org/dev/reference/append_class_pred.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Add a class_pred column — append_class_pred","text":".data data frame tibble. ... One unquoted expressions separated commas capture columns .data containing class probabilities. can treat variable names like positions, can use expressions like x:y select ranges variables use selector functions choose columns. make_class_pred, columns class probabilities selected (order levels object). two_class_pred, vector class probabilities selected. levels character vector class levels. length number selections made ..., length 2 make_two_class_pred(). ordered single logical determine levels regarded ordered (order given). results class_pred object flagged ordered. min_prob single numeric value. probabilities less value (row), row marked equivocal. name single character value name appended class_pred column.","code":""},{"path":"https://probably.tidymodels.org/dev/reference/append_class_pred.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Add a class_pred column — append_class_pred","text":".data extra class_pred column appended onto .","code":""},{"path":"https://probably.tidymodels.org/dev/reference/append_class_pred.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Add a class_pred column — append_class_pred","text":"","code":"# The following two examples are equivalent and demonstrate # the helper, append_class_pred()  library(dplyr) #>  #> Attaching package: ‘dplyr’ #> The following objects are masked from ‘package:stats’: #>  #>     filter, lag #> The following objects are masked from ‘package:base’: #>  #>     intersect, setdiff, setequal, union  species_probs %>%   mutate(     .class_pred = make_class_pred(       .pred_bobcat, .pred_coyote, .pred_gray_fox,       levels = levels(Species),       min_prob = .5     )   ) #> # A tibble: 110 × 5 #>    Species  .pred_bobcat .pred_coyote .pred_gray_fox .class_pred #>    <fct>           <dbl>        <dbl>          <dbl>  <clss_prd> #>  1 gray_fox       0.0976       0.0530         0.849     gray_fox #>  2 gray_fox       0.155        0.139          0.706     gray_fox #>  3 bobcat         0.501        0.0880         0.411       bobcat #>  4 gray_fox       0.256        0              0.744     gray_fox #>  5 gray_fox       0.463        0.287          0.250         [EQ] #>  6 bobcat         0.811        0              0.189       bobcat #>  7 bobcat         0.911        0.0888         0           bobcat #>  8 bobcat         0.898        0.0517         0.0500      bobcat #>  9 bobcat         0.771        0.229          0           bobcat #> 10 bobcat         0.623        0.325          0.0517      bobcat #> # … with 100 more rows  lvls <- levels(species_probs$Species)  append_class_pred(   .data = species_probs,   contains(\".pred_\"),   levels = lvls,   min_prob = .5 ) #> # A tibble: 110 × 5 #>    Species  .pred_bobcat .pred_coyote .pred_gray_fox .class_pred #>    <fct>           <dbl>        <dbl>          <dbl>  <clss_prd> #>  1 gray_fox       0.0976       0.0530         0.849     gray_fox #>  2 gray_fox       0.155        0.139          0.706     gray_fox #>  3 bobcat         0.501        0.0880         0.411       bobcat #>  4 gray_fox       0.256        0              0.744     gray_fox #>  5 gray_fox       0.463        0.287          0.250         [EQ] #>  6 bobcat         0.811        0              0.189       bobcat #>  7 bobcat         0.911        0.0888         0           bobcat #>  8 bobcat         0.898        0.0517         0.0500      bobcat #>  9 bobcat         0.771        0.229          0           bobcat #> 10 bobcat         0.623        0.325          0.0517      bobcat #> # … with 100 more rows"},{"path":"https://probably.tidymodels.org/dev/reference/as_class_pred.html","id":null,"dir":"Reference","previous_headings":"","what":"Coerce to a class_pred object — as_class_pred","title":"Coerce to a class_pred object — as_class_pred","text":"as_class_pred() provides coercion class_pred existing objects.","code":""},{"path":"https://probably.tidymodels.org/dev/reference/as_class_pred.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Coerce to a class_pred object — as_class_pred","text":"","code":"as_class_pred(x, which = integer(), equivocal = \"[EQ]\")"},{"path":"https://probably.tidymodels.org/dev/reference/as_class_pred.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Coerce to a class_pred object — as_class_pred","text":"x factor ordered factor. integer vector specifying locations x declare equivocal. equivocal single character specifying equivocal label used printing.","code":""},{"path":"https://probably.tidymodels.org/dev/reference/as_class_pred.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Coerce to a class_pred object — as_class_pred","text":"","code":"x <- factor(c(\"Yes\", \"No\", \"Yes\", \"Yes\")) as_class_pred(x) #> [1] Yes No  Yes Yes #> Levels: No Yes #> Reportable: 100%"},{"path":"https://probably.tidymodels.org/dev/reference/cal_apply.html","id":null,"dir":"Reference","previous_headings":"","what":"Applies a calibration to a set of pred_class probabilities — cal_apply","title":"Applies a calibration to a set of pred_class probabilities — cal_apply","text":"Applies calibration set pred_class probabilities","code":""},{"path":"https://probably.tidymodels.org/dev/reference/cal_apply.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Applies a calibration to a set of pred_class probabilities — cal_apply","text":"","code":"cal_apply(.data, object, pred_class = NULL, parameters = NULL, ...)  # S3 method for data.frame cal_apply(.data, object, pred_class = NULL, parameters = NULL, ...)  # S3 method for tune_results cal_apply(.data, object, pred_class = NULL, parameters = NULL, ...)  # S3 method for cal_object cal_apply(.data, object, pred_class = NULL, parameters = NULL, ...)"},{"path":"https://probably.tidymodels.org/dev/reference/cal_apply.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Applies a calibration to a set of pred_class probabilities — cal_apply","text":".data object can process calibration object. object calibration object (cal_object). pred_class (Optional) Column identifier hard class predictions (factor vector). column adjusted based changes calibrated probability columns. parameters (Optional)  optional tibble tuning parameter values can used filter predicted values processing. Applies tune_results objects. ... Optional arguments; currently unused.","code":""},{"path":"https://probably.tidymodels.org/dev/reference/cal_apply.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Applies a calibration to a set of pred_class probabilities — cal_apply","text":"currently supports data.frames . extracts truth estimate columns names, levels, calibration object.","code":""},{"path":"https://probably.tidymodels.org/dev/reference/cal_apply.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Applies a calibration to a set of pred_class probabilities — cal_apply","text":"","code":"w_calibration <- cal_estimate_logistic(segment_logistic, Class)  cal_apply(segment_logistic, w_calibration) #> # A tibble: 1,010 × 3 #>    .pred_poor .pred_good Class #>         <dbl>      <dbl> <fct> #>  1      0.974     0.0258 poor  #>  2      0.930     0.0700 poor  #>  3      0.220     0.780  good  #>  4      0.205     0.795  good  #>  5      0.976     0.0244 poor  #>  6      0.590     0.410  good  #>  7      0.777     0.223  good  #>  8      0.135     0.865  good  #>  9      0.977     0.0231 poor  #> 10      0.770     0.230  poor  #> # … with 1,000 more rows"},{"path":"https://probably.tidymodels.org/dev/reference/cal_binary_tables.html","id":null,"dir":"Reference","previous_headings":"","what":"Probability Calibration table — .cal_binary_table_breaks","title":"Probability Calibration table — .cal_binary_table_breaks","text":"Calibration table functions. require data.frame contains predictions probability columns. output another tibble segmented data compares accuracy probability actual outcome.","code":""},{"path":"https://probably.tidymodels.org/dev/reference/cal_binary_tables.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Probability Calibration table — .cal_binary_table_breaks","text":"","code":".cal_binary_table_breaks(   .data,   truth = NULL,   estimate = NULL,   group = NULL,   num_breaks = 10,   conf_level = 0.9,   event_level = c(\"first\", \"second\"),   ... )  .cal_binary_table_logistic(   .data,   truth = NULL,   estimate = NULL,   group = NULL,   conf_level = 0.9,   event_level = c(\"first\", \"second\"),   ... )  .cal_binary_table_windowed(   .data,   truth = NULL,   estimate = NULL,   group = NULL,   window_size = 0.1,   step_size = window_size/2,   conf_level = 0.9,   event_level = c(\"first\", \"second\"),   ... )"},{"path":"https://probably.tidymodels.org/dev/reference/cal_binary_tables.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Probability Calibration table — .cal_binary_table_breaks","text":".data data.frame object containing predictions probability columns. truth column identifier true class results (factor). unquoted column name. estimate column identifier prediction probabilities. unquoted column name group column identifier group results. num_breaks number segments group probabilities. defaults 10. conf_level Confidence level use visualization. defaults 0.9. event_level single string. Either \"first\" \"second\" specify level truth consider \"event\". ... Additional arguments passed tune_results object.","code":""},{"path":"https://probably.tidymodels.org/dev/reference/cal_binary_tables.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Probability Calibration table — .cal_binary_table_breaks","text":".cal_binary_table_breaks() - Splits data bins, based number breaks provided (num_breaks). bins even ranges, starting 0, ending 1. .cal_binary_table_logistic() - Fits logistic spline regression (GAM) data. creates table predictions based 100 probabilities starting 0, ending 1. .cal_binary_table_windowed() - Creates running percentage probability moves across proportion events.","code":""},{"path":"https://probably.tidymodels.org/dev/reference/cal_binary_tables.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Probability Calibration table — .cal_binary_table_breaks","text":"","code":".cal_binary_table_breaks(   segment_logistic,   Class,   .pred_good ) #> # A tibble: 10 × 6 #>    predicted_midpoint event_rate events total  lower  upper #>                 <dbl>      <dbl>  <dbl> <int>  <dbl>  <dbl> #>  1               0.05     0.0350     12   343 0.0208 0.0570 #>  2               0.15     0.0841      9   107 0.0461 0.145  #>  3               0.25     0.324      24    74 0.236  0.426  #>  4               0.35     0.366      26    71 0.272  0.471  #>  5               0.45     0.538      28    52 0.416  0.656  #>  6               0.55     0.473      26    55 0.357  0.591  #>  7               0.65     0.491      27    55 0.374  0.608  #>  8               0.75     0.691      38    55 0.572  0.790  #>  9               0.85     0.722      70    97 0.636  0.794  #> 10               0.95     0.851      86   101 0.779  0.905   .cal_binary_table_logistic(   segment_logistic,   Class,   .pred_good ) #> # A tibble: 101 × 4 #>    estimate      prob     lower     upper #>       <dbl> <dbl[1d]> <dbl[1d]> <dbl[1d]> #>  1     0       0.0219    0.0143    0.0335 #>  2     0.01    0.0246    0.0165    0.0365 #>  3     0.02    0.0276    0.0190    0.0399 #>  4     0.03    0.0310    0.0219    0.0437 #>  5     0.04    0.0347    0.0250    0.0479 #>  6     0.05    0.0389    0.0286    0.0527 #>  7     0.06    0.0435    0.0325    0.0580 #>  8     0.07    0.0487    0.0369    0.0640 #>  9     0.08    0.0544    0.0418    0.0706 #> 10     0.09    0.0608    0.0472    0.0780 #> # … with 91 more rows  .cal_binary_table_windowed(   segment_logistic,   Class,   .pred_good ) #> # A tibble: 21 × 6 #>    predicted_midpoint event_rate events total  lower  upper #>                 <dbl>      <dbl>  <dbl> <int>  <dbl>  <dbl> #>  1              0.025     0.0233      6   258 0.0108 0.0468 #>  2              0.05      0.0350     12   343 0.0208 0.0570 #>  3              0.1       0.0559      8   143 0.0293 0.101  #>  4              0.15      0.0841      9   107 0.0461 0.145  #>  5              0.2       0.195      17    87 0.130  0.280  #>  6              0.25      0.324      24    74 0.236  0.426  #>  7              0.3       0.343      24    70 0.251  0.448  #>  8              0.35      0.366      26    71 0.272  0.471  #>  9              0.4       0.433      29    67 0.331  0.540  #> 10              0.45      0.538      28    52 0.416  0.656  #> # … with 11 more rows"},{"path":"https://probably.tidymodels.org/dev/reference/cal_estimate_beta.html","id":null,"dir":"Reference","previous_headings":"","what":"Uses a Beta calibration model to calculate new probabilities — cal_estimate_beta","title":"Uses a Beta calibration model to calculate new probabilities — cal_estimate_beta","text":"Uses Beta calibration model calculate new probabilities","code":""},{"path":"https://probably.tidymodels.org/dev/reference/cal_estimate_beta.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Uses a Beta calibration model to calculate new probabilities — cal_estimate_beta","text":"","code":"cal_estimate_beta(   .data,   truth = NULL,   shape_params = 2,   location_params = 1,   estimate = dplyr::starts_with(\".pred_\"),   parameters = NULL,   ... )  # S3 method for data.frame cal_estimate_beta(   .data,   truth = NULL,   shape_params = 2,   location_params = 1,   estimate = dplyr::starts_with(\".pred_\"),   parameters = NULL,   ... )  # S3 method for tune_results cal_estimate_beta(   .data,   truth = NULL,   shape_params = 2,   location_params = 1,   estimate = dplyr::starts_with(\".pred_\"),   parameters = NULL,   ... )"},{"path":"https://probably.tidymodels.org/dev/reference/cal_estimate_beta.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Uses a Beta calibration model to calculate new probabilities — cal_estimate_beta","text":".data data.frame object, tune_results object, contains predictions probability columns. truth column identifier true class results (factor). unquoted column name. shape_params Number shape parameters use. Accepted values 1 2. Defaults 2. location_params Number location parameters use. Accepted values 1 0. Defaults 1. estimate vector column identifiers, one dplyr selector functions choose variables contains class probabilities. defaults prefix used tidymodels (.pred_). order identifiers considered order levels truth variable. parameters (Optional)  optional tibble tuning parameter values can used filter predicted values processing. Applies tune_results objects. ... Additional arguments passed models routines used calculate new probabilities.","code":""},{"path":"https://probably.tidymodels.org/dev/reference/cal_estimate_beta.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Uses a Beta calibration model to calculate new probabilities — cal_estimate_beta","text":"function uses betcal::beta_calibration() function, retains resulting model.","code":""},{"path":"https://probably.tidymodels.org/dev/reference/cal_estimate_beta.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Uses a Beta calibration model to calculate new probabilities — cal_estimate_beta","text":"Meelis Kull, Telmo M. Silva Filho, Peter Flach \"Beyond sigmoids: obtain well-calibrated probabilities binary classifiers beta calibration,\" Electronic Journal Statistics 11(2), 5052-5080, (2017)","code":""},{"path":"https://probably.tidymodels.org/dev/reference/cal_estimate_beta.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Uses a Beta calibration model to calculate new probabilities — cal_estimate_beta","text":"","code":"# It will automatically identify the probability columns # if passed a model fitted with tidymodels cal_estimate_beta(segment_logistic, Class) #>  #> ── Probability Calibration  #> Method: Beta #> Type: Binary #> Source class: Data Frame #> Data points: 1,010 #> Truth variable: `Class` #> Estimate variables: #> `.pred_good` ==> good #> `.pred_poor` ==> poor"},{"path":"https://probably.tidymodels.org/dev/reference/cal_estimate_isotonic.html","id":null,"dir":"Reference","previous_headings":"","what":"Uses an Isotonic regression model to calibrate probabilities — cal_estimate_isotonic","title":"Uses an Isotonic regression model to calibrate probabilities — cal_estimate_isotonic","text":"Uses Isotonic regression model calibrate probabilities","code":""},{"path":"https://probably.tidymodels.org/dev/reference/cal_estimate_isotonic.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Uses an Isotonic regression model to calibrate probabilities — cal_estimate_isotonic","text":"","code":"cal_estimate_isotonic(   .data,   truth = NULL,   estimate = dplyr::starts_with(\".pred_\"),   parameters = NULL,   ... )  # S3 method for data.frame cal_estimate_isotonic(   .data,   truth = NULL,   estimate = dplyr::starts_with(\".pred_\"),   parameters = NULL,   ... )  # S3 method for tune_results cal_estimate_isotonic(   .data,   truth = NULL,   estimate = dplyr::starts_with(\".pred_\"),   parameters = NULL,   ... )"},{"path":"https://probably.tidymodels.org/dev/reference/cal_estimate_isotonic.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Uses an Isotonic regression model to calibrate probabilities — cal_estimate_isotonic","text":".data data.frame object, tune_results object, contains predictions probability columns. truth column identifier true class results (factor). unquoted column name. estimate vector column identifiers, one dplyr selector functions choose variables contains class probabilities. defaults prefix used tidymodels (.pred_). order identifiers considered order levels truth variable. parameters (Optional)  optional tibble tuning parameter values can used filter predicted values processing. Applies tune_results objects. ... Additional arguments passed models routines used calculate new probabilities.","code":""},{"path":"https://probably.tidymodels.org/dev/reference/cal_estimate_isotonic.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Uses an Isotonic regression model to calibrate probabilities — cal_estimate_isotonic","text":"function uses stats::isoreg() create obtain calibration values.","code":""},{"path":"https://probably.tidymodels.org/dev/reference/cal_estimate_isotonic.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Uses an Isotonic regression model to calibrate probabilities — cal_estimate_isotonic","text":"Zadrozny, Bianca Elkan, Charles. (2002). Transforming Classifier Scores Accurate Multiclass Probability Estimates. Proceedings ACM SIGKDD International Conference Knowledge Discovery Data Mining.","code":""},{"path":"https://probably.tidymodels.org/dev/reference/cal_estimate_isotonic.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Uses an Isotonic regression model to calibrate probabilities — cal_estimate_isotonic","text":"","code":"# It will automatically identify the probability columns # if passed a model fitted with tidymodels cal_estimate_isotonic(segment_logistic, Class) #>  #> ── Probability Calibration  #> Method: Isotonic #> Type: Binary #> Source class: Data Frame #> Data points: 1,010 #> Unique Probability Values: 76 #> Truth variable: `Class` #> Estimate variables: #> `.pred_good` ==> good #> `.pred_poor` ==> poor # Specify the variable names in a vector of unquoted names cal_estimate_isotonic(segment_logistic, Class, c(.pred_poor, .pred_good)) #>  #> ── Probability Calibration  #> Method: Isotonic #> Type: Binary #> Source class: Data Frame #> Data points: 1,010 #> Unique Probability Values: 78 #> Truth variable: `Class` #> Estimate variables: #> `.pred_good` ==> good #> `.pred_poor` ==> poor # dplyr selector functions are also supported cal_estimate_isotonic(segment_logistic, Class, dplyr::starts_with(\".pred_\")) #>  #> ── Probability Calibration  #> Method: Isotonic #> Type: Binary #> Source class: Data Frame #> Data points: 1,010 #> Unique Probability Values: 74 #> Truth variable: `Class` #> Estimate variables: #> `.pred_good` ==> good #> `.pred_poor` ==> poor"},{"path":"https://probably.tidymodels.org/dev/reference/cal_estimate_isotonic_boot.html","id":null,"dir":"Reference","previous_headings":"","what":"Uses a bootstrapped Isotonic regression model to calibrate probabilities — cal_estimate_isotonic_boot","title":"Uses a bootstrapped Isotonic regression model to calibrate probabilities — cal_estimate_isotonic_boot","text":"Uses bootstrapped Isotonic regression model calibrate probabilities","code":""},{"path":"https://probably.tidymodels.org/dev/reference/cal_estimate_isotonic_boot.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Uses a bootstrapped Isotonic regression model to calibrate probabilities — cal_estimate_isotonic_boot","text":"","code":"cal_estimate_isotonic_boot(   .data,   truth = NULL,   estimate = dplyr::starts_with(\".pred_\"),   times = 10,   parameters = NULL,   ... )  # S3 method for data.frame cal_estimate_isotonic_boot(   .data,   truth = NULL,   estimate = dplyr::starts_with(\".pred_\"),   times = 10,   parameters = NULL,   ... )  # S3 method for tune_results cal_estimate_isotonic_boot(   .data,   truth = NULL,   estimate = dplyr::starts_with(\".pred_\"),   times = 10,   parameters = NULL,   ... )"},{"path":"https://probably.tidymodels.org/dev/reference/cal_estimate_isotonic_boot.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Uses a bootstrapped Isotonic regression model to calibrate probabilities — cal_estimate_isotonic_boot","text":".data data.frame object, tune_results object, contains predictions probability columns. truth column identifier true class results (factor). unquoted column name. estimate vector column identifiers, one dplyr selector functions choose variables contains class probabilities. defaults prefix used tidymodels (.pred_). order identifiers considered order levels truth variable. times Number bootstraps. parameters (Optional)  optional tibble tuning parameter values can used filter predicted values processing. Applies tune_results objects. ... Additional arguments passed models routines used calculate new probabilities.","code":""},{"path":"https://probably.tidymodels.org/dev/reference/cal_estimate_isotonic_boot.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Uses a bootstrapped Isotonic regression model to calibrate probabilities — cal_estimate_isotonic_boot","text":"function uses stats::isoreg() create obtain calibration values. runs isoreg() multiple times, time different seed. results saved inside returned cal_object.","code":""},{"path":"https://probably.tidymodels.org/dev/reference/cal_estimate_isotonic_boot.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Uses a bootstrapped Isotonic regression model to calibrate probabilities — cal_estimate_isotonic_boot","text":"","code":"# It will automatically identify the probability columns # if passed a model fitted with tidymodels cal_estimate_isotonic_boot(segment_logistic, Class) #>  #> ── Probability Calibration  #> Method: Bootstrapped Isotonic Regression #> Type: Binary #> Source class: Data Frame #> Data points: 1,010 #> Truth variable: `Class` #> Estimate variables: #> `.pred_good` ==> good #> `.pred_poor` ==> poor # Specify the variable names in a vector of unquoted names cal_estimate_isotonic_boot(segment_logistic, Class, c(.pred_poor, .pred_good)) #>  #> ── Probability Calibration  #> Method: Bootstrapped Isotonic Regression #> Type: Binary #> Source class: Data Frame #> Data points: 1,010 #> Truth variable: `Class` #> Estimate variables: #> `.pred_good` ==> good #> `.pred_poor` ==> poor # dplyr selector functions are also supported cal_estimate_isotonic_boot(segment_logistic, Class, dplyr::starts_with(\".pred_\")) #>  #> ── Probability Calibration  #> Method: Bootstrapped Isotonic Regression #> Type: Binary #> Source class: Data Frame #> Data points: 1,010 #> Truth variable: `Class` #> Estimate variables: #> `.pred_good` ==> good #> `.pred_poor` ==> poor"},{"path":"https://probably.tidymodels.org/dev/reference/cal_estimate_logistic.html","id":null,"dir":"Reference","previous_headings":"","what":"Uses a logistic regression model to calibrate probabilities — cal_estimate_logistic","title":"Uses a logistic regression model to calibrate probabilities — cal_estimate_logistic","text":"Uses logistic regression model calibrate probabilities","code":""},{"path":"https://probably.tidymodels.org/dev/reference/cal_estimate_logistic.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Uses a logistic regression model to calibrate probabilities — cal_estimate_logistic","text":"","code":"cal_estimate_logistic(   .data,   truth = NULL,   estimate = dplyr::starts_with(\".pred_\"),   smooth = TRUE,   parameters = NULL,   ... )  # S3 method for data.frame cal_estimate_logistic(   .data,   truth = NULL,   estimate = dplyr::starts_with(\".pred_\"),   smooth = TRUE,   parameters = NULL,   ... )  # S3 method for tune_results cal_estimate_logistic(   .data,   truth = NULL,   estimate = dplyr::starts_with(\".pred_\"),   smooth = TRUE,   parameters = NULL,   ... )"},{"path":"https://probably.tidymodels.org/dev/reference/cal_estimate_logistic.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Uses a logistic regression model to calibrate probabilities — cal_estimate_logistic","text":".data data.frame object, tune_results object, contains predictions probability columns. truth column identifier true class results (factor). unquoted column name. estimate vector column identifiers, one dplyr selector functions choose variables contains class probabilities. defaults prefix used tidymodels (.pred_). order identifiers considered order levels truth variable. smooth Applies logistic models. switches logistic spline TRUE, simple logistic regression FALSE. parameters (Optional)  optional tibble tuning parameter values can used filter predicted values processing. Applies tune_results objects. ... Additional arguments passed models routines used calculate new probabilities.","code":""},{"path":"https://probably.tidymodels.org/dev/reference/cal_estimate_logistic.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Uses a logistic regression model to calibrate probabilities — cal_estimate_logistic","text":"function uses existing modeling functions packages create calibration: stats::glm() used smooth set FALSE mgcv::gam() used smooth set TRUE","code":""},{"path":"https://probably.tidymodels.org/dev/reference/cal_estimate_logistic.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Uses a logistic regression model to calibrate probabilities — cal_estimate_logistic","text":"","code":"# It will automatically identify the probability columns # if passed a model fitted with tidymodels cal_estimate_logistic(segment_logistic, Class) #>  #> ── Probability Calibration  #> Method: Logistic Spline #> Type: Binary #> Source class: Data Frame #> Data points: 1,010 #> Truth variable: `Class` #> Estimate variables: #> `.pred_good` ==> good #> `.pred_poor` ==> poor # Specify the variable names in a vector of unquoted names cal_estimate_logistic(segment_logistic, Class, c(.pred_poor, .pred_good)) #>  #> ── Probability Calibration  #> Method: Logistic Spline #> Type: Binary #> Source class: Data Frame #> Data points: 1,010 #> Truth variable: `Class` #> Estimate variables: #> `.pred_good` ==> good #> `.pred_poor` ==> poor # dplyr selector functions are also supported cal_estimate_logistic(segment_logistic, Class, dplyr::starts_with(\".pred_\")) #>  #> ── Probability Calibration  #> Method: Logistic Spline #> Type: Binary #> Source class: Data Frame #> Data points: 1,010 #> Truth variable: `Class` #> Estimate variables: #> `.pred_good` ==> good #> `.pred_poor` ==> poor"},{"path":"https://probably.tidymodels.org/dev/reference/cal_plot_breaks.html","id":null,"dir":"Reference","previous_headings":"","what":"Probability calibration plots via binning — cal_plot_breaks","title":"Probability calibration plots via binning — cal_plot_breaks","text":"plot created assess whether observed rate event predicted probability event model. sequence even, mutually exclusive bins created zero one. bin, data whose predicted probability falls within range bin used calculate observed event rate (along confidence intervals event rate). predictions well calibrated, fitted curve align diagonal line.","code":""},{"path":"https://probably.tidymodels.org/dev/reference/cal_plot_breaks.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Probability calibration plots via binning — cal_plot_breaks","text":"","code":"cal_plot_breaks(   .data,   truth = NULL,   estimate = NULL,   group = NULL,   num_breaks = 10,   conf_level = 0.9,   include_ribbon = TRUE,   include_rug = TRUE,   include_points = TRUE,   event_level = c(\"first\", \"second\"),   ... )  # S3 method for data.frame cal_plot_breaks(   .data,   truth = NULL,   estimate = NULL,   group = NULL,   num_breaks = 10,   conf_level = 0.9,   include_ribbon = TRUE,   include_rug = TRUE,   include_points = TRUE,   event_level = c(\"first\", \"second\"),   ... )  # S3 method for tune_results cal_plot_breaks(   .data,   truth = NULL,   estimate = NULL,   group = NULL,   num_breaks = 10,   conf_level = 0.9,   include_ribbon = TRUE,   include_rug = TRUE,   include_points = TRUE,   event_level = c(\"first\", \"second\"),   ... )"},{"path":"https://probably.tidymodels.org/dev/reference/cal_plot_breaks.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Probability calibration plots via binning — cal_plot_breaks","text":".data data.frame object containing predictions probability columns. truth column identifier true class results (factor). unquoted column name. estimate column identifier prediction probabilities. unquoted column name group column identifier group results. num_breaks number segments group probabilities. defaults 10. conf_level Confidence level use visualization. defaults 0.9. include_ribbon Flag indicates ribbon layer included. defaults TRUE. include_rug Flag indicates Rug layer included. defaults TRUE. plot, top side shows frequency event occurring, bottom frequency event occurring. include_points Flag indicates point layer included. event_level single string. Either \"first\" \"second\" specify level truth consider \"event\". ... Additional arguments passed tune_results object.","code":""},{"path":"https://probably.tidymodels.org/dev/reference/cal_plot_breaks.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Probability calibration plots via binning — cal_plot_breaks","text":"ggplot object.","code":""},{"path":[]},{"path":"https://probably.tidymodels.org/dev/reference/cal_plot_breaks.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Probability calibration plots via binning — cal_plot_breaks","text":"","code":"library(ggplot2) library(dplyr)  cal_plot_breaks(   segment_logistic,   Class,   .pred_good )   cal_plot_logistic(   segment_logistic,   Class,   .pred_good )   cal_plot_windowed(   segment_logistic,   Class,   .pred_good )   # The functions support dplyr groups  model <- glm(Class ~ .pred_good, segment_logistic, family = \"binomial\")  preds <- predict(model, segment_logistic, type = \"response\")  gl <- segment_logistic %>%   mutate(.pred_good = 1 - preds, source = \"glm\")  combined <- bind_rows(mutate(segment_logistic, source = \"original\"), gl)  combined %>%   group_by(source) %>%   cal_plot_logistic(Class, .pred_good)   # The grouping can be faceted in ggplot2 combined %>%   group_by(source) %>%   cal_plot_logistic(Class, .pred_good) +   facet_wrap(~source) +   theme(legend.position = \"\")"},{"path":"https://probably.tidymodels.org/dev/reference/cal_plot_logistic.html","id":null,"dir":"Reference","previous_headings":"","what":"Probability calibration plots via logistic regression — cal_plot_logistic","title":"Probability calibration plots via logistic regression — cal_plot_logistic","text":"logistic regression model fit original outcome data used outcome estimated class probabilities one class used predictor. smooth = TRUE, generalized additive model fit using mgcv::gam() default smoothing method. Otherwise, simple logistic regression used. predictions well calibrated, fitted curve align diagonal line. Confidence intervals fitted line also shown.","code":""},{"path":"https://probably.tidymodels.org/dev/reference/cal_plot_logistic.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Probability calibration plots via logistic regression — cal_plot_logistic","text":"","code":"cal_plot_logistic(   .data,   truth = NULL,   estimate = NULL,   group = NULL,   conf_level = 0.9,   smooth = TRUE,   include_rug = TRUE,   include_ribbon = TRUE,   event_level = c(\"first\", \"second\"),   ... )  # S3 method for data.frame cal_plot_logistic(   .data,   truth = NULL,   estimate = NULL,   group = NULL,   conf_level = 0.9,   smooth = TRUE,   include_rug = TRUE,   include_ribbon = TRUE,   event_level = c(\"first\", \"second\"),   ... )  # S3 method for tune_results cal_plot_logistic(   .data,   truth = NULL,   estimate = NULL,   group = NULL,   conf_level = 0.9,   smooth = TRUE,   include_rug = TRUE,   include_ribbon = TRUE,   event_level = c(\"first\", \"second\"),   ... )"},{"path":"https://probably.tidymodels.org/dev/reference/cal_plot_logistic.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Probability calibration plots via logistic regression — cal_plot_logistic","text":".data data.frame object containing predictions probability columns. truth column identifier true class results (factor). unquoted column name. estimate column identifier prediction probabilities. unquoted column name group column identifier group results. conf_level Confidence level use visualization. defaults 0.9. smooth logical using generalized additive model smooth terms predictor via mgcv::gam() mgcv::s(). include_rug Flag indicates Rug layer included. defaults TRUE. plot, top side shows frequency event occurring, bottom frequency event occurring. include_ribbon Flag indicates ribbon layer included. defaults TRUE. event_level single string. Either \"first\" \"second\" specify level truth consider \"event\". ... Additional arguments passed tune_results object.","code":""},{"path":"https://probably.tidymodels.org/dev/reference/cal_plot_logistic.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Probability calibration plots via logistic regression — cal_plot_logistic","text":"ggplot object.","code":""},{"path":[]},{"path":"https://probably.tidymodels.org/dev/reference/cal_plot_logistic.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Probability calibration plots via logistic regression — cal_plot_logistic","text":"","code":"library(ggplot2) library(dplyr)  cal_plot_logistic(   segment_logistic,   Class,   .pred_good )   cal_plot_logistic(   segment_logistic,   Class,   .pred_good,   smooth = FALSE )"},{"path":"https://probably.tidymodels.org/dev/reference/cal_plot_windowed.html","id":null,"dir":"Reference","previous_headings":"","what":"Probability calibration plots via moving windows — cal_plot_windowed","title":"Probability calibration plots via moving windows — cal_plot_windowed","text":"plot created assess whether observed rate event sample predicted probability event model. similar cal_plot_breaks(), except bins overlapping. sequence bins created zero one. bin, data whose predicted probability falls within range bin used calculate observed event rate (along confidence intervals event rate). predictions well calibrated, fitted curve align diagonal line.","code":""},{"path":"https://probably.tidymodels.org/dev/reference/cal_plot_windowed.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Probability calibration plots via moving windows — cal_plot_windowed","text":"","code":"cal_plot_windowed(   .data,   truth = NULL,   estimate = NULL,   group = NULL,   window_size = 0.1,   step_size = window_size/2,   conf_level = 0.9,   include_ribbon = TRUE,   include_rug = TRUE,   include_points = TRUE,   event_level = c(\"first\", \"second\"),   ... )  # S3 method for data.frame cal_plot_windowed(   .data,   truth = NULL,   estimate = NULL,   group = NULL,   window_size = 0.1,   step_size = window_size/2,   conf_level = 0.9,   include_ribbon = TRUE,   include_rug = TRUE,   include_points = TRUE,   event_level = c(\"first\", \"second\"),   ... )  # S3 method for tune_results cal_plot_windowed(   .data,   truth = NULL,   estimate = NULL,   group = NULL,   window_size = 0.1,   step_size = window_size/2,   conf_level = 0.9,   include_ribbon = TRUE,   include_rug = TRUE,   include_points = TRUE,   event_level = c(\"first\", \"second\"),   ... )"},{"path":"https://probably.tidymodels.org/dev/reference/cal_plot_windowed.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Probability calibration plots via moving windows — cal_plot_windowed","text":".data data.frame object containing predictions probability columns. truth column identifier true class results (factor). unquoted column name. estimate column identifier prediction probabilities. unquoted column name group column identifier group results. window_size size segments. Used windowed probability calculations. defaults 10% segments. step_size gap segments. Used windowed probability calculations. defaults half size window_size conf_level Confidence level use visualization. defaults 0.9. include_ribbon Flag indicates ribbon layer included. defaults TRUE. include_rug Flag indicates Rug layer included. defaults TRUE. plot, top side shows frequency event occurring, bottom frequency event occurring. include_points Flag indicates point layer included. event_level single string. Either \"first\" \"second\" specify level truth consider \"event\". ... Additional arguments passed tune_results object.","code":""},{"path":"https://probably.tidymodels.org/dev/reference/cal_plot_windowed.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Probability calibration plots via moving windows — cal_plot_windowed","text":"ggplot object.","code":""},{"path":[]},{"path":"https://probably.tidymodels.org/dev/reference/cal_plot_windowed.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Probability calibration plots via moving windows — cal_plot_windowed","text":"","code":"library(ggplot2) library(dplyr)  cal_plot_windowed(   segment_logistic,   Class,   .pred_good )   # More breaks cal_plot_windowed(   segment_logistic,   Class,   .pred_good,   window_size = 0.05 )"},{"path":"https://probably.tidymodels.org/dev/reference/class_pred.html","id":null,"dir":"Reference","previous_headings":"","what":"Create a class prediction object — class_pred","title":"Create a class prediction object — class_pred","text":"class_pred() creates class_pred object factor ordered factor. can optionally specify values factor set equivocal.","code":""},{"path":"https://probably.tidymodels.org/dev/reference/class_pred.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Create a class prediction object — class_pred","text":"","code":"class_pred(x = factor(), which = integer(), equivocal = \"[EQ]\")"},{"path":"https://probably.tidymodels.org/dev/reference/class_pred.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Create a class prediction object — class_pred","text":"x factor ordered factor. integer vector specifying locations x declare equivocal. equivocal single character specifying equivocal label used printing.","code":""},{"path":"https://probably.tidymodels.org/dev/reference/class_pred.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Create a class prediction object — class_pred","text":"Equivocal values feel unsure , like exclude performance calculations metrics.","code":""},{"path":"https://probably.tidymodels.org/dev/reference/class_pred.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Create a class prediction object — class_pred","text":"","code":"x <- factor(c(\"Yes\", \"No\", \"Yes\", \"Yes\"))  # Create a class_pred object from a factor class_pred(x) #> [1] Yes No  Yes Yes #> Levels: No Yes #> Reportable: 100%  # Say you aren't sure about that 2nd \"Yes\" value. You could mark it as # equivocal. class_pred(x, which = 3) #> [1] Yes  No   [EQ] Yes  #> Levels: No Yes #> Reportable: 75%  # Maybe you want a different equivocal label class_pred(x, which = 3, equivocal = \"eq_value\") #> [1] Yes      No       eq_value Yes      #> Levels: No Yes #> Reportable: 75%"},{"path":"https://probably.tidymodels.org/dev/reference/is_class_pred.html","id":null,"dir":"Reference","previous_headings":"","what":"Test if an object inherits from class_pred — is_class_pred","title":"Test if an object inherits from class_pred — is_class_pred","text":"is_class_pred() checks object class_pred object.","code":""},{"path":"https://probably.tidymodels.org/dev/reference/is_class_pred.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Test if an object inherits from class_pred — is_class_pred","text":"","code":"is_class_pred(x)"},{"path":"https://probably.tidymodels.org/dev/reference/is_class_pred.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Test if an object inherits from class_pred — is_class_pred","text":"x object.","code":""},{"path":"https://probably.tidymodels.org/dev/reference/is_class_pred.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Test if an object inherits from class_pred — is_class_pred","text":"","code":"x <- class_pred(factor(1:5))  is_class_pred(x) #> [1] TRUE"},{"path":"https://probably.tidymodels.org/dev/reference/levels.class_pred.html","id":null,"dir":"Reference","previous_headings":"","what":"Extract class_pred levels — levels.class_pred","title":"Extract class_pred levels — levels.class_pred","text":"levels class_pred object include equivocal value.","code":""},{"path":"https://probably.tidymodels.org/dev/reference/levels.class_pred.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Extract class_pred levels — levels.class_pred","text":"","code":"# S3 method for class_pred levels(x)"},{"path":"https://probably.tidymodels.org/dev/reference/levels.class_pred.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Extract class_pred levels — levels.class_pred","text":"x class_pred object.","code":""},{"path":"https://probably.tidymodels.org/dev/reference/levels.class_pred.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Extract class_pred levels — levels.class_pred","text":"","code":"x <- class_pred(factor(1:5), which = 1)  # notice that even though `1` is not in the `class_pred` vector, the # level remains from the original factor levels(x) #> [1] \"1\" \"2\" \"3\" \"4\" \"5\""},{"path":"https://probably.tidymodels.org/dev/reference/locate-equivocal.html","id":null,"dir":"Reference","previous_headings":"","what":"Locate equivocal values — locate-equivocal","title":"Locate equivocal values — locate-equivocal","text":"functions provide multiple methods checking equivocal values, finding locations.","code":""},{"path":"https://probably.tidymodels.org/dev/reference/locate-equivocal.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Locate equivocal values — locate-equivocal","text":"","code":"is_equivocal(x)  which_equivocal(x)  any_equivocal(x)"},{"path":"https://probably.tidymodels.org/dev/reference/locate-equivocal.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Locate equivocal values — locate-equivocal","text":"x class_pred object.","code":""},{"path":"https://probably.tidymodels.org/dev/reference/locate-equivocal.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Locate equivocal values — locate-equivocal","text":"is_equivocal() returns logical vector length x TRUE means value equivocal. which_equivocal() returns integer vector specifying locations equivocal values. any_equivocal() returns TRUE equivocal values.","code":""},{"path":"https://probably.tidymodels.org/dev/reference/locate-equivocal.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Locate equivocal values — locate-equivocal","text":"","code":"x <- class_pred(factor(1:10), which = c(2, 5))  is_equivocal(x) #>  [1] FALSE  TRUE FALSE FALSE  TRUE FALSE FALSE FALSE FALSE FALSE  which_equivocal(x) #> [1] 2 5  any_equivocal(x) #> [1] TRUE"},{"path":"https://probably.tidymodels.org/dev/reference/make_class_pred.html","id":null,"dir":"Reference","previous_headings":"","what":"Create a class_pred vector from class probabilities — make_class_pred","title":"Create a class_pred vector from class probabilities — make_class_pred","text":"functions can used convert class probability estimates class_pred objects optional equivocal zone.","code":""},{"path":"https://probably.tidymodels.org/dev/reference/make_class_pred.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Create a class_pred vector from class probabilities — make_class_pred","text":"","code":"make_class_pred(..., levels, ordered = FALSE, min_prob = 1/length(levels))  make_two_class_pred(   estimate,   levels,   threshold = 0.5,   ordered = FALSE,   buffer = NULL )"},{"path":"https://probably.tidymodels.org/dev/reference/make_class_pred.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Create a class_pred vector from class probabilities — make_class_pred","text":"... Numeric vectors corresponding class probabilities. one level levels, assumed vectors order levels. levels character vector class levels. length number selections made ..., length 2 make_two_class_pred(). ordered single logical determine levels regarded ordered (order given). results class_pred object flagged ordered. min_prob single numeric value. probabilities less value (row), row marked equivocal. estimate single numeric vector corresponding class probabilities first level levels. threshold single numeric value threshold call row labeled first value levels. buffer numeric vector length 1 2 buffer around threshold defines equivocal zone (.e., threshold - buffer[1] threshold + buffer[2]). length 1 vector recycled length 2. default, NULL, interpreted equivocal zone.","code":""},{"path":"https://probably.tidymodels.org/dev/reference/make_class_pred.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Create a class_pred vector from class probabilities — make_class_pred","text":"vector class class_pred.","code":""},{"path":"https://probably.tidymodels.org/dev/reference/make_class_pred.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Create a class_pred vector from class probabilities — make_class_pred","text":"","code":"library(dplyr)  good <- segment_logistic$.pred_good lvls <- levels(segment_logistic$Class)  # Equivocal zone of .5 +/- .15 make_two_class_pred(good, lvls, buffer = 0.15) #>    [1] poor poor good good poor [EQ] poor good poor poor good poor poor #>   [14] good poor good poor poor [EQ] poor poor good poor good poor poor #>   [27] good [EQ] good good poor poor [EQ] good good poor poor poor poor #>   [40] poor [EQ] [EQ] poor poor poor poor poor good good poor [EQ] poor #>   [53] poor [EQ] poor [EQ] poor poor [EQ] poor poor good good poor poor #>   [66] [EQ] good poor [EQ] poor good poor [EQ] poor good poor good [EQ] #>   [79] poor [EQ] good poor poor poor good good poor good poor poor poor #>   [92] poor [EQ] good poor [EQ] good [EQ] [EQ] poor good [EQ] poor poor #>  [105] good good good [EQ] good poor poor poor good poor [EQ] poor [EQ] #>  [118] poor good good poor good poor [EQ] poor poor good good poor poor #>  [131] [EQ] [EQ] poor good good poor [EQ] poor [EQ] [EQ] poor [EQ] [EQ] #>  [144] poor [EQ] poor good [EQ] poor poor poor good good poor poor [EQ] #>  [157] good poor poor [EQ] good poor good good poor poor poor [EQ] [EQ] #>  [170] poor good good poor poor [EQ] good poor poor poor poor [EQ] good #>  [183] poor poor poor [EQ] poor good good poor good [EQ] poor good poor #>  [196] poor good poor poor poor good good [EQ] poor poor poor poor poor #>  [209] [EQ] poor good good poor [EQ] poor poor poor good poor good [EQ] #>  [222] poor good good good poor [EQ] poor poor good poor poor poor good #>  [235] good good poor poor poor [EQ] [EQ] poor poor poor [EQ] poor [EQ] #>  [248] good poor poor poor good poor poor good [EQ] good good poor [EQ] #>  [261] poor good good [EQ] [EQ] good poor poor poor poor [EQ] poor poor #>  [274] poor poor [EQ] good poor [EQ] [EQ] poor poor poor good [EQ] poor #>  [287] [EQ] good poor [EQ] poor good [EQ] good poor poor poor good poor #>  [300] good [EQ] poor poor poor good poor poor poor [EQ] good poor poor #>  [313] good poor good poor [EQ] poor poor [EQ] [EQ] poor poor poor poor #>  [326] good [EQ] poor poor [EQ] poor poor poor poor poor [EQ] good [EQ] #>  [339] poor good poor good [EQ] good poor [EQ] poor poor poor poor poor #>  [352] good good [EQ] [EQ] poor good poor good poor poor poor poor good #>  [365] poor poor poor poor poor poor poor [EQ] poor poor poor poor poor #>  [378] poor poor good poor poor poor poor poor poor [EQ] good poor poor #>  [391] poor [EQ] [EQ] good poor poor poor poor poor poor good [EQ] [EQ] #>  [404] poor poor poor poor poor poor poor good good poor poor poor poor #>  [417] poor [EQ] poor poor poor good [EQ] good good poor poor poor good #>  [430] good good good poor good poor poor poor poor poor poor good [EQ] #>  [443] [EQ] poor good good [EQ] [EQ] poor poor good poor poor good poor #>  [456] good poor poor poor good poor poor poor poor good poor poor good #>  [469] poor good good good poor good poor good good good poor poor good #>  [482] poor poor poor poor poor poor good [EQ] poor [EQ] poor poor poor #>  [495] good poor [EQ] poor [EQ] poor poor poor poor poor poor good good #>  [508] poor [EQ] [EQ] [EQ] poor poor poor poor good [EQ] good poor poor #>  [521] good good poor [EQ] poor poor [EQ] poor good poor poor good poor #>  [534] poor poor poor poor good [EQ] poor good good poor poor good poor #>  [547] good good poor poor good poor good poor [EQ] poor poor poor poor #>  [560] [EQ] good poor good good poor poor poor good good poor poor good #>  [573] [EQ] [EQ] poor [EQ] poor poor poor [EQ] poor good poor good good #>  [586] poor poor poor poor good [EQ] good poor good [EQ] [EQ] poor poor #>  [599] [EQ] [EQ] poor good good good [EQ] good poor poor poor [EQ] poor #>  [612] good poor good [EQ] poor poor poor good good poor good poor poor #>  [625] poor poor poor good poor [EQ] good [EQ] good poor good poor good #>  [638] poor poor [EQ] [EQ] poor poor poor poor poor good good poor poor #>  [651] poor poor poor poor good good poor good poor good poor good poor #>  [664] poor poor [EQ] poor poor good poor poor good good good poor poor #>  [677] poor [EQ] poor good good [EQ] good poor good poor poor poor [EQ] #>  [690] poor poor [EQ] [EQ] good [EQ] poor good poor poor good good poor #>  [703] [EQ] poor good poor poor [EQ] [EQ] [EQ] poor good poor good good #>  [716] good good poor poor poor good poor good poor poor [EQ] poor poor #>  [729] poor poor poor poor [EQ] good good good poor [EQ] poor poor poor #>  [742] good poor good good [EQ] poor good poor [EQ] poor poor poor [EQ] #>  [755] good good poor poor poor good poor good poor good [EQ] poor good #>  [768] [EQ] poor [EQ] good poor good [EQ] poor good poor poor good poor #>  [781] poor good good good poor poor poor poor poor good poor [EQ] poor #>  [794] poor poor good [EQ] poor good [EQ] [EQ] good poor good poor poor #>  [807] poor poor poor poor poor [EQ] poor good poor poor poor poor good #>  [820] poor good good poor poor poor poor poor good [EQ] poor good poor #>  [833] poor poor poor poor poor poor [EQ] poor poor poor poor poor good #>  [846] good good poor poor poor poor poor poor poor poor good [EQ] [EQ] #>  [859] [EQ] poor good [EQ] poor poor poor [EQ] good poor good good poor #>  [872] good poor poor good [EQ] [EQ] [EQ] poor poor poor poor [EQ] good #>  [885] poor good poor good poor poor poor poor good poor poor poor poor #>  [898] poor poor poor poor [EQ] poor poor [EQ] good [EQ] good poor poor #>  [911] poor good [EQ] poor good poor poor poor poor good poor poor good #>  [924] good poor poor good poor [EQ] poor good poor good good good poor #>  [937] poor good good poor poor [EQ] [EQ] poor good poor poor good [EQ] #>  [950] [EQ] poor [EQ] poor good [EQ] [EQ] poor good poor poor poor good #>  [963] poor poor poor poor good poor poor [EQ] poor poor poor good good #>  [976] poor [EQ] poor poor poor good poor poor good poor [EQ] good good #>  [989] good good poor [EQ] poor good poor poor poor poor good good good #> [1002] good good poor good [EQ] good poor poor good #> Levels: good poor #> Reportable: 83.2%  # Equivocal zone of c(.5 - .05, .5 + .15) make_two_class_pred(good, lvls, buffer = c(0.05, 0.15)) #>    [1] poor poor good good poor poor poor good poor poor good poor poor #>   [14] good poor good poor poor [EQ] poor poor good poor good poor poor #>   [27] good poor good good poor poor [EQ] good good poor poor poor poor #>   [40] poor [EQ] poor poor poor poor poor poor good good poor [EQ] poor #>   [53] poor poor poor poor poor poor [EQ] poor poor good good poor poor #>   [66] poor good poor [EQ] poor good poor [EQ] poor good poor good poor #>   [79] poor [EQ] good poor poor poor good good poor good poor poor poor #>   [92] poor [EQ] good poor [EQ] good [EQ] poor poor good [EQ] poor poor #>  [105] good good good poor good poor poor poor good poor poor poor [EQ] #>  [118] poor good good poor good poor [EQ] poor poor good good poor poor #>  [131] [EQ] poor poor good good poor [EQ] poor [EQ] [EQ] poor poor [EQ] #>  [144] poor [EQ] poor good poor poor poor poor good good poor poor poor #>  [157] good poor poor [EQ] good poor good good poor poor poor [EQ] poor #>  [170] poor good good poor poor [EQ] good poor poor poor poor [EQ] good #>  [183] poor poor poor [EQ] poor good good poor good poor poor good poor #>  [196] poor good poor poor poor good good poor poor poor poor poor poor #>  [209] poor poor good good poor [EQ] poor poor poor good poor good [EQ] #>  [222] poor good good good poor [EQ] poor poor good poor poor poor good #>  [235] good good poor poor poor [EQ] poor poor poor poor [EQ] poor poor #>  [248] good poor poor poor good poor poor good [EQ] good good poor [EQ] #>  [261] poor good good [EQ] poor good poor poor poor poor [EQ] poor poor #>  [274] poor poor [EQ] good poor poor [EQ] poor poor poor good [EQ] poor #>  [287] [EQ] good poor poor poor good [EQ] good poor poor poor good poor #>  [300] good [EQ] poor poor poor good poor poor poor [EQ] good poor poor #>  [313] good poor good poor poor poor poor [EQ] [EQ] poor poor poor poor #>  [326] good poor poor poor [EQ] poor poor poor poor poor [EQ] good [EQ] #>  [339] poor good poor good poor good poor [EQ] poor poor poor poor poor #>  [352] good good poor [EQ] poor good poor good poor poor poor poor good #>  [365] poor poor poor poor poor poor poor poor poor poor poor poor poor #>  [378] poor poor good poor poor poor poor poor poor [EQ] good poor poor #>  [391] poor [EQ] [EQ] good poor poor poor poor poor poor good [EQ] [EQ] #>  [404] poor poor poor poor poor poor poor good good poor poor poor poor #>  [417] poor [EQ] poor poor poor good [EQ] good good poor poor poor good #>  [430] good good good poor good poor poor poor poor poor poor good [EQ] #>  [443] poor poor good good [EQ] [EQ] poor poor good poor poor good poor #>  [456] good poor poor poor good poor poor poor poor good poor poor good #>  [469] poor good good good poor good poor good good good poor poor good #>  [482] poor poor poor poor poor poor good poor poor [EQ] poor poor poor #>  [495] good poor poor poor [EQ] poor poor poor poor poor poor good good #>  [508] poor [EQ] [EQ] [EQ] poor poor poor poor good poor good poor poor #>  [521] good good poor poor poor poor [EQ] poor good poor poor good poor #>  [534] poor poor poor poor good poor poor good good poor poor good poor #>  [547] good good poor poor good poor good poor poor poor poor poor poor #>  [560] poor good poor good good poor poor poor good good poor poor good #>  [573] [EQ] poor poor poor poor poor poor poor poor good poor good good #>  [586] poor poor poor poor good [EQ] good poor good poor [EQ] poor poor #>  [599] poor [EQ] poor good good good [EQ] good poor poor poor poor poor #>  [612] good poor good poor poor poor poor good good poor good poor poor #>  [625] poor poor poor good poor poor good poor good poor good poor good #>  [638] poor poor [EQ] [EQ] poor poor poor poor poor good good poor poor #>  [651] poor poor poor poor good good poor good poor good poor good poor #>  [664] poor poor [EQ] poor poor good poor poor good good good poor poor #>  [677] poor [EQ] poor good good [EQ] good poor good poor poor poor poor #>  [690] poor poor poor [EQ] good [EQ] poor good poor poor good good poor #>  [703] poor poor good poor poor [EQ] [EQ] poor poor good poor good good #>  [716] good good poor poor poor good poor good poor poor [EQ] poor poor #>  [729] poor poor poor poor [EQ] good good good poor poor poor poor poor #>  [742] good poor good good poor poor good poor [EQ] poor poor poor [EQ] #>  [755] good good poor poor poor good poor good poor good [EQ] poor good #>  [768] [EQ] poor [EQ] good poor good [EQ] poor good poor poor good poor #>  [781] poor good good good poor poor poor poor poor good poor [EQ] poor #>  [794] poor poor good [EQ] poor good poor poor good poor good poor poor #>  [807] poor poor poor poor poor poor poor good poor poor poor poor good #>  [820] poor good good poor poor poor poor poor good [EQ] poor good poor #>  [833] poor poor poor poor poor poor poor poor poor poor poor poor good #>  [846] good good poor poor poor poor poor poor poor poor good [EQ] poor #>  [859] [EQ] poor good poor poor poor poor [EQ] good poor good good poor #>  [872] good poor poor good [EQ] poor [EQ] poor poor poor poor [EQ] good #>  [885] poor good poor good poor poor poor poor good poor poor poor poor #>  [898] poor poor poor poor poor poor poor poor good poor good poor poor #>  [911] poor good [EQ] poor good poor poor poor poor good poor poor good #>  [924] good poor poor good poor [EQ] poor good poor good good good poor #>  [937] poor good good poor poor poor poor poor good poor poor good [EQ] #>  [950] poor poor [EQ] poor good [EQ] poor poor good poor poor poor good #>  [963] poor poor poor poor good poor poor [EQ] poor poor poor good good #>  [976] poor poor poor poor poor good poor poor good poor poor good good #>  [989] good good poor [EQ] poor good poor poor poor poor good good good #> [1002] good good poor good [EQ] good poor poor good #> Levels: good poor #> Reportable: 89.8%  # These functions are useful alongside dplyr::mutate() segment_logistic %>%   mutate(     .class_pred = make_two_class_pred(       estimate = .pred_good,       levels = levels(Class),       buffer = 0.15     )   ) #> # A tibble: 1,010 × 4 #>    .pred_poor .pred_good Class .class_pred #>         <dbl>      <dbl> <fct>  <clss_prd> #>  1    0.986      0.0142  poor         poor #>  2    0.897      0.103   poor         poor #>  3    0.118      0.882   good         good #>  4    0.102      0.898   good         good #>  5    0.991      0.00914 poor         poor #>  6    0.633      0.367   good         [EQ] #>  7    0.770      0.230   good         poor #>  8    0.00842    0.992   good         good #>  9    0.995      0.00458 poor         poor #> 10    0.765      0.235   poor         poor #> # … with 1,000 more rows  # Multi-class example # Note that we provide class probability columns in the same # order as the levels species_probs %>%   mutate(     .class_pred = make_class_pred(       .pred_bobcat, .pred_coyote, .pred_gray_fox,       levels = levels(Species),       min_prob = .5     )   ) #> # A tibble: 110 × 5 #>    Species  .pred_bobcat .pred_coyote .pred_gray_fox .class_pred #>    <fct>           <dbl>        <dbl>          <dbl>  <clss_prd> #>  1 gray_fox       0.0976       0.0530         0.849     gray_fox #>  2 gray_fox       0.155        0.139          0.706     gray_fox #>  3 bobcat         0.501        0.0880         0.411       bobcat #>  4 gray_fox       0.256        0              0.744     gray_fox #>  5 gray_fox       0.463        0.287          0.250         [EQ] #>  6 bobcat         0.811        0              0.189       bobcat #>  7 bobcat         0.911        0.0888         0           bobcat #>  8 bobcat         0.898        0.0517         0.0500      bobcat #>  9 bobcat         0.771        0.229          0           bobcat #> 10 bobcat         0.623        0.325          0.0517      bobcat #> # … with 100 more rows"},{"path":"https://probably.tidymodels.org/dev/reference/probably-package.html","id":null,"dir":"Reference","previous_headings":"","what":"probably: Tools for Post-Processing Class Probability Estimates — probably-package","title":"probably: Tools for Post-Processing Class Probability Estimates — probably-package","text":"Models can improved post-processing class probabilities, : recalibration, conversion hard probabilities, assessment equivocal zones, activities. 'probably' contains tools conducting operations.","code":""},{"path":[]},{"path":"https://probably.tidymodels.org/dev/reference/probably-package.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"probably: Tools for Post-Processing Class Probability Estimates — probably-package","text":"Maintainer: Max Kuhn max@rstudio.com Authors: Davis Vaughan davis@rstudio.com contributors: RStudio [copyright holder, funder]","code":""},{"path":"https://probably.tidymodels.org/dev/reference/reexports.html","id":null,"dir":"Reference","previous_headings":"","what":"Objects exported from other packages — reexports","title":"Objects exported from other packages — reexports","text":"objects imported packages. Follow links see documentation. generics .factor, .ordered","code":""},{"path":"https://probably.tidymodels.org/dev/reference/reportable_rate.html","id":null,"dir":"Reference","previous_headings":"","what":"Calculate the reportable rate — reportable_rate","title":"Calculate the reportable rate — reportable_rate","text":"reportable rate defined percentage class predictions equivocal.","code":""},{"path":"https://probably.tidymodels.org/dev/reference/reportable_rate.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Calculate the reportable rate — reportable_rate","text":"","code":"reportable_rate(x)"},{"path":"https://probably.tidymodels.org/dev/reference/reportable_rate.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Calculate the reportable rate — reportable_rate","text":"x class_pred object.","code":""},{"path":"https://probably.tidymodels.org/dev/reference/reportable_rate.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Calculate the reportable rate — reportable_rate","text":"reportable rate calculated (n_not_equivocal / n).","code":""},{"path":"https://probably.tidymodels.org/dev/reference/reportable_rate.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Calculate the reportable rate — reportable_rate","text":"","code":"x <- class_pred(factor(1:5), which = c(1, 2))  # 3 / 5 reportable_rate(x) #> [1] 0.6"},{"path":"https://probably.tidymodels.org/dev/reference/segment_naive_bayes.html","id":null,"dir":"Reference","previous_headings":"","what":"Image segmentation predictions — segment_naive_bayes","title":"Image segmentation predictions — segment_naive_bayes","text":"Image segmentation predictions","code":""},{"path":"https://probably.tidymodels.org/dev/reference/segment_naive_bayes.html","id":"source","dir":"Reference","previous_headings":"","what":"Source","title":"Image segmentation predictions — segment_naive_bayes","text":"Hill, LaPan, Li Haney (2007). Impact image segmentation high-content screening data quality SK-BR-3 cells, BMC Bioinformatics, Vol. 8, pg. 340, https://bmcbioinformatics.biomedcentral.com/articles/10.1186/1471-2105-8-340.","code":""},{"path":"https://probably.tidymodels.org/dev/reference/segment_naive_bayes.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Image segmentation predictions — segment_naive_bayes","text":"segment_naive_bayes,segment_logistic tibble","code":""},{"path":"https://probably.tidymodels.org/dev/reference/segment_naive_bayes.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Image segmentation predictions — segment_naive_bayes","text":"objects contain test set predictions cell segmentation data Hill, LaPan, Li Haney (2007). data frame results different models (naive Bayes logistic regression).","code":""},{"path":"https://probably.tidymodels.org/dev/reference/segment_naive_bayes.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Image segmentation predictions — segment_naive_bayes","text":"","code":"data(segment_naive_bayes) data(segment_logistic)"},{"path":"https://probably.tidymodels.org/dev/reference/species_probs.html","id":null,"dir":"Reference","previous_headings":"","what":"Predictions on animal species — species_probs","title":"Predictions on animal species — species_probs","text":"Predictions animal species","code":""},{"path":"https://probably.tidymodels.org/dev/reference/species_probs.html","id":"source","dir":"Reference","previous_headings":"","what":"Source","title":"Predictions on animal species — species_probs","text":"Reid, R. E. B. (2015). morphometric modeling approach distinguishing among bobcat, coyote gray fox scats. Wildlife Biology, 21(5), 254-262","code":""},{"path":"https://probably.tidymodels.org/dev/reference/species_probs.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Predictions on animal species — species_probs","text":"species_probs tibble","code":""},{"path":"https://probably.tidymodels.org/dev/reference/species_probs.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Predictions on animal species — species_probs","text":"data holdout predictions resampling animal scat data Reid (2015) based C5.0 classification model.","code":""},{"path":"https://probably.tidymodels.org/dev/reference/species_probs.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Predictions on animal species — species_probs","text":"","code":"data(species_probs) str(species_probs) #> tibble [110 × 4] (S3: tbl_df/tbl/data.frame) #>  $ Species       : Factor w/ 3 levels \"bobcat\",\"coyote\",..: 3 3 1 3 3 1 1 1 1 1 ... #>  $ .pred_bobcat  : num [1:110] 0.0976 0.1548 0.5007 0.2563 0.4627 ... #>  $ .pred_coyote  : num [1:110] 0.053 0.139 0.088 0 0.287 ... #>  $ .pred_gray_fox: num [1:110] 0.849 0.706 0.411 0.744 0.25 ..."},{"path":"https://probably.tidymodels.org/dev/reference/threshold_perf.html","id":null,"dir":"Reference","previous_headings":"","what":"Generate performance metrics across probability thresholds — threshold_perf","title":"Generate performance metrics across probability thresholds — threshold_perf","text":"threshold_perf() can take set class probability predictions determine performance characteristics across different values probability threshold existing groups.","code":""},{"path":"https://probably.tidymodels.org/dev/reference/threshold_perf.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Generate performance metrics across probability thresholds — threshold_perf","text":"","code":"threshold_perf(.data, ...)  # S3 method for data.frame threshold_perf(   .data,   truth,   estimate,   thresholds = NULL,   na_rm = TRUE,   event_level = \"first\",   ... )"},{"path":"https://probably.tidymodels.org/dev/reference/threshold_perf.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Generate performance metrics across probability thresholds — threshold_perf","text":".data tibble, potentially grouped. ... Currently unused. truth column identifier true two-class results (factor). unquoted column name. estimate column identifier predicted class probabilities (numeric). unquoted column name. thresholds numeric vector values probability threshold. unspecified, series values 0.5 1.0 used. Note: argument used, must named. na_rm single logical: missing data removed? event_level single string. Either \"first\" \"second\" specify level truth consider \"event\".","code":""},{"path":"https://probably.tidymodels.org/dev/reference/threshold_perf.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Generate performance metrics across probability thresholds — threshold_perf","text":"tibble columns: .threshold, .estimator, .metric, .estimate existing groups.","code":""},{"path":"https://probably.tidymodels.org/dev/reference/threshold_perf.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Generate performance metrics across probability thresholds — threshold_perf","text":"Note global option yardstick.event_first used determine level event interest. details, see Relevant level section yardstick::sens(). currently calculated metrics : yardstick::j_index() yardstick::sens() yardstick::spec() distance = (1 - sens) ^ 2 + (1 - spec) ^ 2","code":""},{"path":"https://probably.tidymodels.org/dev/reference/threshold_perf.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Generate performance metrics across probability thresholds — threshold_perf","text":"","code":"library(dplyr) data(\"segment_logistic\")  # Set the threshold to 0.6 # > 0.6 = good # < 0.6 = poor threshold_perf(segment_logistic, Class, .pred_good, thresholds = 0.6) #> # A tibble: 4 × 4 #>   .threshold .metric  .estimator .estimate #>        <dbl> <chr>    <chr>          <dbl> #> 1        0.6 sens     binary         0.639 #> 2        0.6 spec     binary         0.869 #> 3        0.6 j_index  binary         0.508 #> 4        0.6 distance binary         0.148  # Set the threshold to multiple values thresholds <- seq(0.5, 0.9, by = 0.1)  segment_logistic %>%   threshold_perf(Class, .pred_good, thresholds) #> # A tibble: 20 × 4 #>    .threshold .metric  .estimator .estimate #>         <dbl> <chr>    <chr>          <dbl> #>  1        0.5 sens     binary         0.714 #>  2        0.6 sens     binary         0.639 #>  3        0.7 sens     binary         0.561 #>  4        0.8 sens     binary         0.451 #>  5        0.9 sens     binary         0.249 #>  6        0.5 spec     binary         0.825 #>  7        0.6 spec     binary         0.869 #>  8        0.7 spec     binary         0.911 #>  9        0.8 spec     binary         0.937 #> 10        0.9 spec     binary         0.977 #> 11        0.5 j_index  binary         0.539 #> 12        0.6 j_index  binary         0.508 #> 13        0.7 j_index  binary         0.472 #> 14        0.8 j_index  binary         0.388 #> 15        0.9 j_index  binary         0.226 #> 16        0.5 distance binary         0.112 #> 17        0.6 distance binary         0.148 #> 18        0.7 distance binary         0.201 #> 19        0.8 distance binary         0.306 #> 20        0.9 distance binary         0.565  # ---------------------------------------------------------------------------  # It works with grouped data frames as well # Let's mock some resampled data resamples <- 5  mock_resamples <- resamples %>%   replicate(     expr = sample_n(segment_logistic, 100, replace = TRUE),     simplify = FALSE   ) %>%   bind_rows(.id = \"resample\")  resampled_threshold_perf <- mock_resamples %>%   group_by(resample) %>%   threshold_perf(Class, .pred_good, thresholds)  resampled_threshold_perf #> # A tibble: 100 × 5 #>    resample .threshold .metric .estimator .estimate #>    <chr>         <dbl> <chr>   <chr>          <dbl> #>  1 1               0.5 sens    binary         0.719 #>  2 1               0.6 sens    binary         0.656 #>  3 1               0.7 sens    binary         0.625 #>  4 1               0.8 sens    binary         0.469 #>  5 1               0.9 sens    binary         0.344 #>  6 2               0.5 sens    binary         0.556 #>  7 2               0.6 sens    binary         0.472 #>  8 2               0.7 sens    binary         0.472 #>  9 2               0.8 sens    binary         0.333 #> 10 2               0.9 sens    binary         0.278 #> # … with 90 more rows  # Average over the resamples resampled_threshold_perf %>%   group_by(.metric, .threshold) %>%   summarise(.estimate = mean(.estimate)) #> `summarise()` has grouped output by '.metric'. You can override using the #> `.groups` argument. #> # A tibble: 20 × 3 #> # Groups:   .metric [4] #>    .metric  .threshold .estimate #>    <chr>         <dbl>     <dbl> #>  1 distance        0.5     0.149 #>  2 distance        0.6     0.199 #>  3 distance        0.7     0.239 #>  4 distance        0.8     0.347 #>  5 distance        0.9     0.533 #>  6 j_index         0.5     0.495 #>  7 j_index         0.6     0.471 #>  8 j_index         0.7     0.456 #>  9 j_index         0.8     0.370 #> 10 j_index         0.9     0.263 #> 11 sens            0.5     0.657 #> 12 sens            0.6     0.572 #> 13 sens            0.7     0.520 #> 14 sens            0.8     0.416 #> 15 sens            0.9     0.272 #> 16 spec            0.5     0.837 #> 17 spec            0.6     0.899 #> 18 spec            0.7     0.936 #> 19 spec            0.8     0.954 #> 20 spec            0.9     0.991"},{"path":"https://probably.tidymodels.org/dev/news/index.html","id":"probably-development-version","dir":"Changelog","previous_headings":"","what":"probably (development version)","title":"probably (development version)","text":"Adds cal_apply() function. uses output calibration function, applies data frame, tune_results object. Adds 5 model calibration remediation methods: Logistic, Logistic Spline, Isotonic, Isotonic Bootstrapped, Beta. currently support data frames, binary models . Adds model calibration diagnostic functions. implement three methods: binning probabilities, fitting logistic spline model probabilities, creating running percentage data. three new plotting functions, three table functions. supports data.frames tune_results objects.","code":""},{"path":"https://probably.tidymodels.org/dev/news/index.html","id":"probably-010","dir":"Changelog","previous_headings":"","what":"probably 0.1.0","title":"probably 0.1.0","text":"CRAN release: 2022-08-29 Max Kuhn now maintainer (#49). Re-licensed package GPL-2 MIT. copyright holders RStudio employees give consent. Fixed bug make_class_pred() make_two_class_pred() validate levels argument (#42). threshold_perf() now explicit event_level argument rather respecting now deprecated yardstick.event_first global option (#45). Bumped minimum required R version >=3.4.0 align rest tidyverse. Updated testthat 3e (#44).","code":""},{"path":"https://probably.tidymodels.org/dev/news/index.html","id":"probably-006","dir":"Changelog","previous_headings":"","what":"probably 0.0.6","title":"probably 0.0.6","text":"CRAN release: 2020-06-05 class_pred objects now comparable ordered levels. Equivocal values generally considered smallest value ordering. NA values can considered smaller vec_order(na_value = \"smallest\") used.","code":""},{"path":"https://probably.tidymodels.org/dev/news/index.html","id":"probably-005","dir":"Changelog","previous_headings":"","what":"probably 0.0.5","title":"probably 0.0.5","text":"CRAN release: 2020-05-14 Internal cleanup compatible vctrs 0.3.0.","code":""},{"path":"https://probably.tidymodels.org/dev/news/index.html","id":"probably-004","dir":"Changelog","previous_headings":"","what":"probably 0.0.4","title":"probably 0.0.4","text":"CRAN release: 2020-01-13 Suggest modeldata package, lending_club dataset moved removed recipes. Use testthat::verify_output() test expecting specific vctrs error avoid failure CRAN error changes future.","code":""},{"path":"https://probably.tidymodels.org/dev/news/index.html","id":"probably-003","dir":"Changelog","previous_headings":"","what":"probably 0.0.3","title":"probably 0.0.3","text":"CRAN release: 2019-07-07 probably brought date vctrs 0.2.0. vctrs update many function name changes, required internal refactoring, minimal external changes. one user facing change comes casting one class_pred object another class_pred, factor. previously warning thrown x levels exist , error now generated. consistent vctrs behavior converting one factor another.","code":"x  <- class_pred(factor(\"a\")) to <- class_pred(factor(\"to\")) vec_cast(x, to) #> Error: Lossy cast from <class_pred> to <class_pred>. #> Locations: 1"},{"path":"https://probably.tidymodels.org/dev/news/index.html","id":"probably-002","dir":"Changelog","previous_headings":"","what":"probably 0.0.2","title":"probably 0.0.2","text":"CRAN release: 2019-03-07","code":""},{"path":"https://probably.tidymodels.org/dev/news/index.html","id":"bug-fixes-0-0-2","dir":"Changelog","previous_headings":"","what":"Bug fixes","title":"probably 0.0.2","text":"failing test relying R 3.6 change sample() corrected. rlang warning threshold_perf() fixed. small R 3.1 issue vctrs fixed.","code":""},{"path":"https://probably.tidymodels.org/dev/news/index.html","id":"probably-001","dir":"Changelog","previous_headings":"","what":"probably 0.0.1","title":"probably 0.0.1","text":"CRAN release: 2018-12-18 First release","code":""}]
